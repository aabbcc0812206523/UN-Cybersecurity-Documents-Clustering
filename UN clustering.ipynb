{
  "cells": [
    {
      "metadata": {
        "_cell_guid": "6e686432-bea7-4768-b47d-47a243c59408",
        "collapsed": true,
        "_uuid": "28169e87ee391fd12d23533ab014e97c03650ba7",
        "trusted": false
      },
      "cell_type": "code",
      "source": "%matplotlib inline\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import HashingVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import Normalizer\nfrom sklearn import metrics\n\nfrom sklearn.cluster import KMeans, MiniBatchKMeans\n\nimport logging\nimport sys\nfrom time import time\n\nimport numpy as np\n\n# Display progress logs on stdout\nlogging.basicConfig(level=logging.INFO,\n                    format='%(asctime)s %(levelname)s %(message)s')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "3fd53d00-efb2-4164-ad9d-eceaeea51a5e",
        "_uuid": "a9eb94eee08211284076c0638b93cf0ee0927e3d",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "import os, re, string\nfrom nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n\ndef read_text():\n    path = \"../input/\"\n    filenames = os.listdir(path)\n    \n    sentences=[]\n    validchars = string.ascii_letters + string.digits + ' ' + ',.!?'\n    for filename in filenames:\n        file = open(path+filename, 'r')\n        str = file.read()\n        clean = ''.join(c for c in str if c in validchars)\n        sents = sent_tokenize(clean)\n        sentences += sents\n    return sentences\n\ndata = read_text()\nprint(\"%d documents\" % len(data))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ff460438f88376841e632317d5f93286ac4dbc70",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "data[:5]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "4af0177e-b676-4c77-a9cb-c8915aca5e3c",
        "_uuid": "c0d6c83c56c75ba5d8b2fc385a64a928d84c31be",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "print(\"Extracting features from the training dataset using a sparse vectorizer\")\nt0 = time()\nvectorizer = TfidfVectorizer(max_df=0.5, max_features=10000,\n                             min_df=2, stop_words='english',\n                             use_idf=True)\nX = vectorizer.fit_transform(data)\n\nprint(\"done in %fs\" % (time() - t0))\nprint(\"n_samples: %d, n_features: %d\" % X.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8f55652611269b1500fc59fe63b5b0b487f5fa30"
      },
      "cell_type": "markdown",
      "source": "## Dimensionality Reduction using LSA"
    },
    {
      "metadata": {
        "_uuid": "5e746c95589a338347823fdaad1d6a2c344c394c",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "n_components = int(X.shape[0]*0.1)\nprint(\"Performing dimensionality reduction using LSA, # of components = {}\".format(n_components))\nt0 = time()\n# Vectorizer results are normalized, which makes KMeans behave as\n# spherical k-means for better results. Since LSA/SVD results are\n# not normalized, we have to redo the normalization.\nsvd = TruncatedSVD(n_components)\nnormalizer = Normalizer(copy=False)\nlsa = make_pipeline(svd, normalizer)\n\nX = lsa.fit_transform(X)\n\nprint(\"done in %fs\" % (time() - t0))\n\nexplained_variance = svd.explained_variance_ratio_.sum()\nprint(\"Explained variance of the SVD step: {}%\".format(\n    int(explained_variance * 100)))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "bb45dfbb-4b3b-4585-914e-fc1505357b98",
        "_uuid": "6dfab83b7f409de0fa9eea591a397ecc9af88112"
      },
      "cell_type": "markdown",
      "source": "## Clustering"
    },
    {
      "metadata": {
        "_cell_guid": "9804273f-d02a-43db-b4ab-4a65936f30b3",
        "_uuid": "d6ce3ad85b7045d82376cdbdcb2e0d91b539d9d7",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "num_clusters = 10\nkm = MiniBatchKMeans(n_clusters=num_clusters, init='k-means++', n_init=1,\n                     init_size=1000, batch_size=1000)\n\nprint(\"Clustering sparse data with %s\" % km)\n\nt0 = time()\nkm.fit(X)\nprint(\"done in %0.3fs\" % (time() - t0))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_uuid": "711485c04a503b6bf444c7970b3985d8c7255893",
        "trusted": false
      },
      "cell_type": "code",
      "source": "print(\"Top terms per cluster:\")\n\nif n_components:\n    original_space_centroids = svd.inverse_transform(km.cluster_centers_)\n    order_centroids = original_space_centroids.argsort()[:, ::-1]\nelse:\n    order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n\nterms = vectorizer.get_feature_names()\nfor i in range(num_clusters):\n    print(\"Cluster %d:\" % i, end='')\n    for ind in order_centroids[i, :10]:\n        print(' %s' % terms[ind], end='')\n    print()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "80441d8f-4ab5-4c3c-97f1-60290c54185c",
        "collapsed": true,
        "_uuid": "165e49e6e949e8169f46375b36718cc846d3d913",
        "trusted": false
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}